#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆçŸ¥è¯†å›¾è°±æ„å»ºMCPæœåŠ¡å™¨
ç”¨äºæµ‹è¯•å’Œè§£å†³åˆå§‹åŒ–é—®é¢˜
"""
import asyncio
import json
import os
import sys
import time
from typing import Any
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ§åˆ¶å°ç¼–ç 
if sys.platform == "win32":
    os.system("chcp 65001 > nul")
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

from mcp.server import NotificationOptions, Server
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

# åŸæœ‰æ¨¡å—
from kg_utils import KnowledgeGraphBuilder

# æ–°å¢åˆ†ææ¨¡å—
try:
    from content_enhancement.analysis_pipeline import analyze_knowledge_graph, AnalysisConfig
    ANALYSIS_AVAILABLE = True
    print("âœ… åˆ†ææ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    ANALYSIS_AVAILABLE = False
    print(f"âŒ åˆ†ææ¨¡å—åŠ è½½å¤±è´¥: {e}")
    print("é«˜çº§åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
except Exception as e:
    ANALYSIS_AVAILABLE = False
    print(f"âŒ åˆ†ææ¨¡å—åˆå§‹åŒ–é”™è¯¯: {e}")
    print("é«˜çº§åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")

# å…¨å±€ç»„ä»¶
try:
    kg_builder = KnowledgeGraphBuilder(api_key=os.getenv("OPENAI_API_KEY"))
    print("âœ… æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
    raise

# åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
server = Server("knowledge-graph-builder-simple")

@server.list_tools()
async def handle_list_tools() -> list[Tool]:
    """åˆ—å‡ºå¯ç”¨çš„å·¥å…·"""
    tools = []
    
    # å¦‚æœåˆ†ææ¨¡å—å¯ç”¨ï¼Œæ·»åŠ é«˜çº§åˆ†æå·¥å…·
    if ANALYSIS_AVAILABLE:
        tools.append(
            Tool(
                name="build_and_analyze_kg",
                description="æ„å»ºçŸ¥è¯†å›¾è°±å¹¶è¿›è¡Œé«˜çº§åˆ†æ",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "text": {
                            "type": "string",
                            "description": "è¦å¤„ç†çš„æ–‡æœ¬æ•°æ®"
                        }
                    },
                    "required": ["text"]
                }
            )
        )
    
    return tools

@server.call_tool()
async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    if name == "build_and_analyze_kg" and ANALYSIS_AVAILABLE:
        return await build_and_analyze_kg_simple(arguments)
    else:
        raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")

async def build_and_analyze_kg_simple(arguments: dict[str, Any]) -> list[TextContent]:
    """ç®€åŒ–ç‰ˆä¸€ä½“åŒ–å·¥å…·"""
    try:
        text = arguments.get("text", "")
        
        if not text.strip():
            return [TextContent(
                type="text",
                text=json.dumps({
                    "success": False,
                    "error": "è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
                }, ensure_ascii=False, indent=2)
            )]
        
        start_time = time.time()
        
        # æ„å»ºåŸºç¡€çŸ¥è¯†å›¾è°±
        kg_result = await kg_builder.build_graph(text, use_llm=True)
        
        if not kg_result["entities"] and not kg_result["triples"]:
            return [TextContent(
                type="text",
                text=json.dumps({
                    "success": False,
                    "error": "æ— æ³•ä»è¾“å…¥æ–‡æœ¬ä¸­æå–åˆ°æœ‰æ•ˆçš„å®ä½“æˆ–å…³ç³»"
                }, ensure_ascii=False, indent=2)
            )]
        
        # è½¬æ¢æ•°æ®æ ¼å¼ç”¨äºåˆ†æ
        entities = [
            {
                'name': entity,
                'type': 'unknown',
                'attributes': {},
                'relations': []
            }
            for entity in kg_result["entities"]
        ]
        
        relations = [
            {
                'name': triple.relation,
                'source': triple.head,
                'target': triple.tail,
                'type': 'unknown'
            }
            for triple in kg_result["triples"]
        ]
        
        # é…ç½®åˆ†æå‚æ•°
        config = AnalysisConfig(
            enable_global_analysis=True,
            enable_detail_analysis=True,
            similarity_threshold=0.3,
            max_recommendations=10
        )
        
        # æ‰§è¡Œé«˜çº§åˆ†æ
        analysis_result = await analyze_knowledge_graph(
            text, entities, relations, config
        )
        
        processing_time = time.time() - start_time
        
        # æ„å»ºç»“æœ
        result = {
            "success": True,
            "input_text": text,
            "processing_time": round(processing_time, 3),
            "knowledge_graph": {
                "entities_count": len(kg_result["entities"]),
                "relations_count": len(kg_result["relations"]),
                "triples_count": len(kg_result["triples"]),
                "entities": kg_result["entities"],
                "relations": kg_result["relations"]
            },
            "analysis_results": {
                "timestamp": analysis_result.timestamp,
                "quality_score": analysis_result.quality_metrics.get('overall_score', 0),
                "total_issues": analysis_result.quality_metrics.get('issue_count', 0),
                "critical_issues": analysis_result.quality_metrics.get('critical_issues', 0),
                "recommendations_count": len(analysis_result.integrated_recommendations),
                "top_recommendations": analysis_result.integrated_recommendations[:5]
            },
            "detailed_analysis": {
                "global_analysis": analysis_result.global_analysis_results is not None,
                "detail_analysis": analysis_result.detail_analysis_results is not None,
                "all_recommendations": analysis_result.integrated_recommendations
            }
        }
        
        return [TextContent(
            type="text",
            text=json.dumps(result, ensure_ascii=False, indent=2)
        )]
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        return [TextContent(
            type="text",
            text=json.dumps({
                "success": False,
                "error": str(e),
                "error_details": error_details
            }, ensure_ascii=False, indent=2)
        )]

async def main():
    """è¿è¡ŒæœåŠ¡å™¨"""
    print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆçŸ¥è¯†å›¾è°±æ„å»ºæœåŠ¡å™¨")
    print(f"ğŸ”§ é«˜çº§åˆ†æåŠŸèƒ½: {'âœ… å¯ç”¨' if ANALYSIS_AVAILABLE else 'âŒ ä¸å¯ç”¨'}")
    
    try:
        # éªŒè¯ç»„ä»¶çŠ¶æ€
        print("ğŸ”§ éªŒè¯ç»„ä»¶çŠ¶æ€...")
        if not hasattr(kg_builder, 'build_graph'):
            raise RuntimeError("çŸ¥è¯†å›¾è°±æ„å»ºå™¨æœªæ­£ç¡®åˆå§‹åŒ–")
        print("âœ… æ‰€æœ‰ç»„ä»¶éªŒè¯é€šè¿‡")
        
        # ä½¿ç”¨ stdio ä¼ è¾“è¿è¡ŒæœåŠ¡å™¨
        print("ğŸ”— å¯åŠ¨MCPæœåŠ¡å™¨...")
        async with stdio_server() as (read_stream, write_stream):
            # æ·»åŠ åˆå§‹åŒ–å»¶è¿Ÿç¡®ä¿æ‰€æœ‰ç»„ä»¶å°±ç»ª
            await asyncio.sleep(0.1)
            
            await server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="knowledge-graph-builder-simple",
                    server_version="1.0.0",
                    capabilities=server.get_capabilities(
                        notification_options=NotificationOptions(),
                        experimental_capabilities={}
                    ),
                ),
            )
            
    except Exception as e:
        print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    asyncio.run(main()) 