#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - éªŒè¯çŸ¥è¯†å›¾è°±å¢å¼ºåŠŸèƒ½
"""

import asyncio
import json
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "content_enhancement"))

def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")
    
    try:
        # æµ‹è¯•åŸæœ‰æ¨¡å—
        from data_quality import DataQualityAssessor
        from knowledge_completion import KnowledgeCompletor
        from kg_utils import KnowledgeGraphBuilder
        print("âœ… åŸæœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•æ–°å¢æ¨¡å—
        from content_enhancement.global_analysis import GlobalAnalyzer
        from content_enhancement.entity_detail_analyzer import EntityDetailAnalyzer
        from content_enhancement.analysis_pipeline import analyze_knowledge_graph, AnalysisConfig
        print("âœ… æ–°å¢åˆ†ææ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


async def test_analysis_pipeline():
    """æµ‹è¯•åˆ†ææµç¨‹"""
    print("\nğŸ“Š æµ‹è¯•åˆ†ææµç¨‹...")
    
    try:
        from content_enhancement.analysis_pipeline import analyze_knowledge_graph, AnalysisConfig
        
        # æµ‹è¯•æ•°æ®
        test_text = """
        å¼ ä¸‰æ˜¯é˜¿é‡Œå·´å·´çš„é«˜çº§å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£äº‘è®¡ç®—å¹³å°çš„å¼€å‘ã€‚
        ä»–æ¯•ä¸šäºæ¸…åå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸“ä¸šï¼Œæœ‰10å¹´çš„å·¥ä½œç»éªŒã€‚
        é˜¿é‡Œå·´å·´æˆç«‹äº1999å¹´ï¼Œæ€»éƒ¨ä½äºæ­å·ï¼Œæ˜¯ä¸­å›½æœ€å¤§çš„ç”µå•†å…¬å¸ä¹‹ä¸€ã€‚
        """
        
        test_entities = [
            {
                'name': 'å¼ ä¸‰',
                'type': 'Person',
                'attributes': {'èŒä¸š': 'é«˜çº§å·¥ç¨‹å¸ˆ', 'å·¥ä½œå¹´é™': '10å¹´'},
                'relations': ['å·¥ä½œäº', 'æ¯•ä¸šäº']
            },
            {
                'name': 'é˜¿é‡Œå·´å·´',
                'type': 'Organization',
                'attributes': {'æˆç«‹æ—¶é—´': '1999å¹´', 'æ€»éƒ¨': 'æ­å·'},
                'relations': ['é›‡ä½£', 'ä½äº']
            },
            {
                'name': 'æ¸…åå¤§å­¦',
                'type': 'Organization',
                'attributes': {'ç±»å‹': 'é«˜ç­‰é™¢æ ¡'},
                'relations': ['åŸ¹å…»']
            }
        ]
        
        test_relations = [
            {
                'name': 'å·¥ä½œäº',
                'source': 'å¼ ä¸‰',
                'target': 'é˜¿é‡Œå·´å·´',
                'type': 'é›‡ä½£å…³ç³»'
            },
            {
                'name': 'æ¯•ä¸šäº',
                'source': 'å¼ ä¸‰',
                'target': 'æ¸…åå¤§å­¦',
                'type': 'æ•™è‚²å…³ç³»'
            }
        ]
        
        # æ‰§è¡Œåˆ†æ
        config = AnalysisConfig(
            enable_global_analysis=True,
            enable_detail_analysis=True,
            similarity_threshold=0.3,
            max_recommendations=10
        )
        
        result = await analyze_knowledge_graph(test_text, test_entities, test_relations, config)
        
        print(f"âœ… åˆ†æå®Œæˆ!")
        print(f"   - è´¨é‡è¯„åˆ†: {result.quality_metrics['overall_score']:.1f}")
        print(f"   - å‘ç°é—®é¢˜: {result.quality_metrics['issue_count']} ä¸ª")
        print(f"   - å»ºè®®æ•°é‡: {len(result.integrated_recommendations)} ä¸ª")
        
        if result.integrated_recommendations:
            print("   - å‰3ä¸ªå»ºè®®:")
            for i, rec in enumerate(result.integrated_recommendations[:3], 1):
                print(f"     {i}. [{rec['priority']}] {rec['description']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†ææµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_original_functions():
    """æµ‹è¯•åŸæœ‰åŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•åŸæœ‰åŠŸèƒ½...")
    
    try:
        from data_quality import DataQualityAssessor
        from kg_utils import KnowledgeGraphBuilder
        
        # æµ‹è¯•æ•°æ®è´¨é‡è¯„ä¼°
        assessor = DataQualityAssessor()
        quality_result = await assessor.assess_quality("å¼ ä¸‰æ˜¯é˜¿é‡Œå·´å·´çš„å·¥ç¨‹å¸ˆ")
        print(f"âœ… æ•°æ®è´¨é‡è¯„ä¼°: {quality_result['quality_score']:.2f}")
        
        # æµ‹è¯•çŸ¥è¯†å›¾è°±æ„å»º
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            builder = KnowledgeGraphBuilder(api_key=api_key)
            kg_result = await builder.build_graph("å¼ ä¸‰æ˜¯é˜¿é‡Œå·´å·´çš„å·¥ç¨‹å¸ˆ", use_llm=True)
            print(f"âœ… çŸ¥è¯†å›¾è°±æ„å»º: {len(kg_result['entities'])} ä¸ªå®ä½“, {len(kg_result['triples'])} ä¸ªä¸‰å…ƒç»„")
        else:
            print("âš ï¸  æœªè®¾ç½®OPENAI_API_KEYï¼Œè·³è¿‡LLMç›¸å…³æµ‹è¯•")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸæœ‰åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    print("\nğŸ“ æ£€æŸ¥æ–‡ä»¶ç»“æ„...")
    
    required_files = [
        "kg_server.py",
        "kg_server_enhanced.py", 
        "content_enhancement/global_analysis.py",
        "content_enhancement/entity_detail_analyzer.py",
        "content_enhancement/analysis_pipeline.py"
    ]
    
    all_exist = True
    for file_path in required_files:
        if Path(file_path).exists():
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path} ä¸å­˜åœ¨")
            all_exist = False
    
    return all_exist


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("\nğŸ“¦ æ£€æŸ¥ä¾èµ–...")
    
    required_packages = [
        "networkx",
        "numpy", 
        "scipy",
        "jieba",
        "asyncio"
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} ç¼ºå¤±")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nâš ï¸  ç¼ºå°‘ä¾èµ–: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: uv sync")
        return False
    
    return True


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•çŸ¥è¯†å›¾è°±å¢å¼ºåŠŸèƒ½\n")
    
    tests = [
        ("æ–‡ä»¶ç»“æ„", test_file_structure),
        ("ä¾èµ–æ£€æŸ¥", check_dependencies),
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("åŸæœ‰åŠŸèƒ½", test_original_functions),
        ("åˆ†ææµç¨‹", test_analysis_pipeline),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"{'='*50}")
        print(f"æµ‹è¯•: {test_name}")
        print(f"{'='*50}")
        
        if asyncio.iscoroutinefunction(test_func):
            result = await test_func()
        else:
            result = test_func()
        
        if result:
            passed += 1
            print(f"âœ… {test_name} é€šè¿‡")
        else:
            print(f"âŒ {test_name} å¤±è´¥")
    
    print(f"\n{'='*50}")
    print(f"ğŸ¯ æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print(f"{'='*50}")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤:")
        print("   åŸç‰ˆ: uv run kg_server.py")
        print("   å¢å¼ºç‰ˆ: uv run kg_server_enhanced.py")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    
    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1) 